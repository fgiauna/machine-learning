{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bdcaac",
   "metadata": {},
   "source": [
    "Florent Giauna (AMSD) et Zewei Lin (MLSD)\n",
    "\n",
    "Appentissage supervisé pour des données avec classes déséquilibrées\n",
    "\n",
    "Séance 2 - Prédiction de churn, Partie I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e6b59b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:34:25.279442Z",
     "start_time": "2023-03-22T17:34:25.275196Z"
    }
   },
   "outputs": [],
   "source": [
    "#Librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Pré-traitement\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#Sélection de modèles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Modèles\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Métriques\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da61c30",
   "metadata": {},
   "source": [
    "# Dataset : Credit fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab913eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:34:30.261926Z",
     "start_time": "2023-03-22T17:34:29.159935Z"
    }
   },
   "outputs": [],
   "source": [
    "#Chargement des données \n",
    "df = pd.read_csv('data/creditcard_v2.csv')\n",
    "\n",
    "#Séparation du dataset en jeux d'entraînement et de test\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=7, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c9653bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:34:32.425778Z",
     "start_time": "2023-03-22T17:34:31.291950Z"
    }
   },
   "outputs": [],
   "source": [
    "#Liste des variables\n",
    "var_list = list(X_train)\n",
    "    \n",
    "#Redimensionnement des variables quantitatives\n",
    "scaler = RobustScaler()\n",
    "\n",
    "for var in var_list:\n",
    "    X_train[[var]] = scaler.fit_transform(X_train[[var]])\n",
    "    X_test[[var]] = scaler.transform(X_test[[var]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c3ad1",
   "metadata": {},
   "source": [
    "Les variables contenant de nombreux outliers RobustScaler est plus approprié que StandardScaler et MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76bba78",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## (a) Pour chaque approche, avec les hyper-paramètres par défaut, évaluez la prédiction du churn sur la base de l’AUC (Area Under the Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31e50f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La courbe ROC (Receiver operating characteristic) permet de mesurer la performance d'un classifieur en contrebalançant la proportion de vrais positifs correctement prédits (recall ou sensitivity) par la proportion de vrais négatifs correctement prédits (specificity ou inverse de la précision). Le meilleur algorithme maximise l'aire sous la courbe ROC: l'AUC. \n",
    "\n",
    "Cependant utiliser la courbe ROC et l'AUC lorsque le jeu de données est déséquilibré pose problème (cf. Saito, T., & Rehmsmeier, M. (2015). The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. PloS one, 10(3), e0118432. https://doi.org/10.1371/journal.pone.0118432). La courbe Precision-Recall (PR) et le PR AUC sont plus adaptés. Il s'agit de la moyenne des précisions sur les classes, calculée à chaque seuil de recall.\n",
    "\n",
    "Dans notre cas, la PR AUC (average precision) est donc une meilleure mesure pour l'instant (avant d'essayer des techniques d'upsampling et de downsampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13363388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:06:01.455108Z",
     "start_time": "2023-03-22T17:02:00.986731Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree \n",
      "Average precision (PR AUC): 0.5602304654507083 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisiticRegression \n",
      "Average precision (PR AUC): 0.751853214438474 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC \n",
      "Average precision (PR AUC): 0.7425441922405724 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Algorithmes à utiliser\n",
    "clfs = {'DecisionTree': DecisionTreeClassifier(random_state=7),\n",
    "        'LogisiticRegression': LogisticRegression(random_state=7),\n",
    "        'LinearSVC' : LinearSVC(random_state=7)}\n",
    "\n",
    "#Evaluation de la performance de chaque algorithme à partir de l'average precision (PR AUC)\n",
    "for key, clf in clfs.items():\n",
    "    clf_results = cross_validate(clf, X_train, y_train, scoring='average_precision', cv=5)\n",
    "    print(key, \n",
    "          \"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean(),\n",
    "          \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a544d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le dataset étant volumineux, LinearSVC est la seule méthode de SVM utilisable. La documentation de scikit-learn précise que pour sklearn.svm.SVC() \"The fit time scales at least quadratically with the number of samples and may be impractical beyond tens of thousands of samples\". https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e8562",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les résultats obtenus par défaut par la régression logistique et le SVM sont encourageants. L'utilisation de différents hyper-paramètres peut permettre de les améliorer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640cff54",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## (b) Pour chaque approche, définissez un modèle performant en recherchant de bons hyper-paramètres via un grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08fea84",
   "metadata": {
    "hidden": true
   },
   "source": [
    "L'hyper-paramètre 'class_weight' fixé à 'balanced' permet de limiter le déséquilibre et de donner plus de poids à une classification correcte de la classe minortiaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb4f9b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:51:39.091675Z",
     "start_time": "2023-03-22T17:46:47.323631Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'random_state': 7} \n",
      "Average precision (PR AUC): 0.7183737945447246\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle d'arbre de décision\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'criterion': ['gini', 'entropy'], \n",
    "              'max_depth': [1,5,7,9,15,25,30],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_tree, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ad886a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:06:32.696385Z",
     "start_time": "2023-03-22T18:01:35.408657Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.7339315  0.68737194 0.69092713        nan        nan 0.68991018\n",
      "        nan        nan        nan 0.73390485 0.68445966 0.69115104\n",
      "        nan        nan 0.6911504         nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.73518734 0.68719484 0.69414217        nan        nan 0.69364722\n",
      "        nan        nan        nan 0.73594627 0.68516295 0.69458277\n",
      "        nan        nan 0.69454299        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'random_state': 7, 'solver': 'lbfgs'} \n",
      "Average precision (PR AUC): 0.7339314988792072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle de régression logistique\n",
    "clf_logreg = LogisticRegression()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'penalty':['l2', 'l1', 'elasticnet'],\n",
    "              'C':[0.01, 0.1, 1],\n",
    "              'solver': ['lbfgs', 'sag', 'saga'],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_logreg, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bc4d202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:30:45.721158Z",
     "start_time": "2023-03-22T18:09:18.311656Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py\", line 261, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LinearSVC must be a str among {'l2', 'l1'}. Got 'elasticnet' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.68762366        nan        nan 0.71570018        nan\n",
      "        nan 0.71171275        nan        nan 0.71262389        nan\n",
      "        nan 0.67881614        nan        nan 0.67315123        nan]\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.68554751        nan        nan 0.71467132        nan\n",
      "        nan 0.71478679        nan        nan 0.71583364        nan\n",
      "        nan 0.67536318        nan        nan 0.68840138        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'C': 0.1, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 7} \n",
      "Average precision (PR AUC): 0.7157001813949233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle SVC sans kernel\n",
    "clf_svc = LinearSVC()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'loss': ['hinge', 'squared_hinge'],\n",
    "              'C': [0.1, 1, 10],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_svc, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02037d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:31:34.869652Z",
     "start_time": "2023-03-22T18:31:32.095515Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.7314798136819697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du meilleur modèle\n",
    "clf = LogisticRegression(C=0.1, class_weight='balanced', penalty='l2', solver='lbfgs', random_state=7)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0eb7cf34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:31:48.114358Z",
     "start_time": "2023-03-22T18:31:48.106788Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55373  1491]\n",
      " [   11    87]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4e87be1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:32:06.505460Z",
     "start_time": "2023-03-22T18:32:06.465307Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     56864\n",
      "           1       0.06      0.89      0.10        98\n",
      "\n",
      "    accuracy                           0.97     56962\n",
      "   macro avg       0.53      0.93      0.55     56962\n",
      "weighted avg       1.00      0.97      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da61b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le F1 score est la moyenne harmonique entre la précision (proportion de vrais positifs correctement prédits sur tous les positifs prédits) et le recall (la proportion de vrais positifs correctement prédits parmi tous les vrais positifs). Il faut prendre en compte le macro average pour avoir une idée de la performance du classfieur sur les deux classes.\n",
    "\n",
    "Les différents hyperparamètres ont forcé le modèle à trouver des exemples de la classe minoritaire. Mais au prix d'énormément de faux négatifs. La précision sur la classe minoritaire n'est que de 6%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a425a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataset : Bank marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58f5c076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:32:25.659138Z",
     "start_time": "2023-03-22T18:32:25.597326Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Chargement des données \n",
    "df = pd.read_csv('data/bank-additional-full_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20ba7c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:32:26.686541Z",
     "start_time": "2023-03-22T18:32:26.669181Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Séparation du dataset en jeux d'entraînement et de test\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=7, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e31c832a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:32:27.920784Z",
     "start_time": "2023-03-22T18:32:27.916941Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Liste des variables catégorielles nominales\n",
    "var_nom = list(X_train.select_dtypes(['object']).columns)\n",
    "var_nom += ['age', 'duration', 'pdays']\n",
    "\n",
    "#Liste des variables quantitatives\n",
    "var_quant = ['campaign', 'cons.conf.idx', 'cons.price.idx', 'emp.var.rate', \n",
    "             'euribor3m', 'nr.employed', 'previous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e8995e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:32:29.496227Z",
     "start_time": "2023-03-22T18:32:29.299018Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Encodage des variables nominales \n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "\n",
    "for var in var_nom:\n",
    "    ohe_train = ohe.fit_transform(X_train[[var]])\n",
    "    X_train = pd.concat([X_train, ohe_train],axis=1).drop(columns=[var])\n",
    "    ohe_test = ohe.transform(X_test[[var]])\n",
    "    X_test = pd.concat([X_test, ohe_test],axis=1).drop(columns=[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c631337e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:32:30.593990Z",
     "start_time": "2023-03-22T18:32:30.525999Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Redimensionnement des variables quantitatives\n",
    "scaler = RobustScaler()\n",
    "\n",
    "for var in var_quant:\n",
    "    X_train[[var]] = scaler.fit_transform(X_train[[var]])\n",
    "    X_test[[var]] = scaler.transform(X_test[[var]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e88de3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les variables n'ayant pas de distribution gaussienne et le jeu de données contenant de nombreux outliers RobustScaler est plus approprié que StandardScaler et MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3a850",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (a) Pour chaque approche, avec les hyper-paramètres par défaut, évaluez la prédiction du churn sur la base de l’AUC (Area Under the Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52dd91",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La courbe ROC (Receiver operating characteristic) permet de mesurer la performance d'un classifieur en contrebalançant la proportion de vrais positifs correctement prédits (recall ou sensitivity) par la proportion de vrais négatifs correctement prédits (specificity ou inverse de la précision). Le meilleur algorithme maximise l'aire sous la courbe ROC: l'AUC. \n",
    "\n",
    "Cependant utiliser la courbe ROC et l'AUC lorsque le jeu de données est déséquilibré pose problème (cf. Saito, T., & Rehmsmeier, M. (2015). The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. PloS one, 10(3), e0118432. https://doi.org/10.1371/journal.pone.0118432). La courbe Precision-Recall (PR) et le PR AUC sont plus adaptés. Il s'agit de la moyenne des précisions sur les classes, calculée à chaque seuil de recall.\n",
    "\n",
    "Dans notre cas, la PR AUC (average precision) est donc une meilleure mesure pour l'instant (avant d'essayer des techniques d'upsampling et de downsampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6da1129e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:32:45.890008Z",
     "start_time": "2023-03-22T18:32:38.498586Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree \n",
      "Average precision (PR AUC): 0.2501548881235589 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisiticRegression \n",
      "Average precision (PR AUC): 0.5609490485292269 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC \n",
      "Average precision (PR AUC): 0.5689709935233397 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Algorithmes à utiliser\n",
    "clfs = {'DecisionTree': DecisionTreeClassifier(random_state=7),\n",
    "        'LogisiticRegression': LogisticRegression(random_state=7),\n",
    "        'LinearSVC' : LinearSVC(random_state=7)}\n",
    "\n",
    "#Evaluation de la performance de chaque algorithme à partir de l'average precision (PR AUC)\n",
    "for key, clf in clfs.items():\n",
    "    clf_results = cross_validate(clf, X_train, y_train, scoring='average_precision', cv=5)\n",
    "    print(key, \n",
    "          \"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean(),\n",
    "          \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b682e44",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le dataset étant volumineux, LinearSVC est la seule méthode de SVM utilisable. La documentation de scikit-learn précise que pour sklearn.svm.SVC() \"The fit time scales at least quadratically with the number of samples and may be impractical beyond tens of thousands of samples\". https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf8d2cf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les résultats obtenus par défaut par la régression logistique et le SVM sont encourageants. L'utilisation de différents hyper-paramètres peut permettre de les améliorer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712dd733",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (b) Pour chaque approche, définissez un modèle performant en recherchant de bons hyper-paramètres via un grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5118d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "L'hyper-paramètre 'class_weight' fixé à 'balanced' permet de limiter le déséquilibre et de donner plus de poids à une classification correcte de la classe minortiaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5c9e22a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:38:08.568105Z",
     "start_time": "2023-03-22T18:38:01.332865Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'random_state': 7} \n",
      "Average precision (PR AUC): 0.5486338066206959\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle d'arbre de décision\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'criterion': ['gini', 'entropy'], \n",
    "              'max_depth': [1,5,7,9,15,25,50,70],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_tree, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e81e465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:49:45.125975Z",
     "start_time": "2023-03-22T18:48:04.193607Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "75 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.55092305 0.55075773 0.55034052        nan        nan 0.55034052\n",
      "        nan        nan        nan 0.5509925  0.55075773 0.55034052\n",
      "        nan        nan 0.55034052        nan        nan        nan\n",
      " 0.55091189 0.55075773 0.55034052        nan        nan 0.55034052\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.55628535 0.55618185 0.55560047        nan        nan 0.55560054\n",
      "        nan        nan        nan 0.55630117 0.5561819  0.55560052\n",
      "        nan        nan 0.55560052        nan        nan        nan\n",
      " 0.55623139 0.5561819  0.55560052        nan        nan 0.55560052\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'C': 1000000.0, 'class_weight': 'balanced', 'penalty': 'l2', 'random_state': 7, 'solver': 'lbfgs'} \n",
      "Average precision (PR AUC): 0.5509924963917635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle de régression logistique\n",
    "clf_logreg = LogisticRegression()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'penalty':['l2', 'l1', 'elasticnet'],\n",
    "              'C':[1e5, 1e6, 1e7],\n",
    "              'solver': ['lbfgs', 'sag', 'saga'],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_logreg, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f951de4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:48:00.073973Z",
     "start_time": "2023-03-22T18:47:16.136517Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py\", line 261, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LinearSVC must be a str among {'l2', 'l1'}. Got 'elasticnet' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.52520043        nan        nan 0.54527671        nan\n",
      "        nan 0.52329957        nan        nan 0.54574853        nan\n",
      "        nan 0.51562476        nan        nan 0.53708791        nan]\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.52820792        nan        nan 0.55120419        nan\n",
      "        nan 0.52622529        nan        nan 0.5518976         nan\n",
      "        nan 0.52040466        nan        nan 0.54559683        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'C': 1, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 7} \n",
      "Average precision (PR AUC): 0.545748530638497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle SVC sans kernel\n",
    "clf_svc = LinearSVC()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'loss': ['hinge', 'squared_hinge'],\n",
    "              'C': [0.1, 1, 10],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_svc, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6b185999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:51:10.098114Z",
     "start_time": "2023-03-22T18:51:09.481939Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.5517747972278378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du meilleur modèle\n",
    "clf = LogisticRegression(C=1e6, class_weight='balanced', penalty='l2', solver='lbfgs', random_state=7)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a4cdec67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:51:25.600961Z",
     "start_time": "2023-03-22T18:51:25.597603Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5745 1565]\n",
      " [ 116  812]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d51c139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:51:32.691318Z",
     "start_time": "2023-03-22T18:51:32.680437Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87      7310\n",
      "           1       0.34      0.88      0.49       928\n",
      "\n",
      "    accuracy                           0.80      8238\n",
      "   macro avg       0.66      0.83      0.68      8238\n",
      "weighted avg       0.91      0.80      0.83      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505f3bd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le F1 score est la moyenne harmonique entre la précision (proportion de vrais positifs correctement prédits sur tous les positifs prédits) et le recall (la proportion de vrais positifs correctement prédits parmi tous les vrais positifs). Il faut prendre en compte le macro average pour avoir une idée de la performance du classfieur sur les deux classes.\n",
    "\n",
    "Les différents hyperparamètres ont forcé le modèle à trouver des exemples de la classe minoritaire. Mais au prix d'énormément de faux négatifs. La précision sur la classe minoritaire n'est que de 34%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63906f82",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataset : Employee attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43bf574e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:51:41.990186Z",
     "start_time": "2023-03-22T18:51:41.982612Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Chargement des données \n",
    "df = pd.read_csv('data/whole_data_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81fba04d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:51:43.463201Z",
     "start_time": "2023-03-22T18:51:43.459929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Liste des variables quantitatives\n",
    "var_quant = ['Age', 'DistanceFromHome', 'MonthlyIncome', 'NumCompaniesWorked', \n",
    "            'PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear', \n",
    "            'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "\n",
    "#Liste des variables qualitatives\n",
    "var_cat = ['JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction',\n",
    "           'WorkLifeBalance', 'BusinessTravel', 'Department', 'Education', \n",
    "           'EducationField', 'Gender', 'MaritalStatus', 'JobLevel', 'JobRole', 'StockOptionLevel']\n",
    "\n",
    "#Liste des variables qualitatives ordinales\n",
    "var_ord = ['JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction',\n",
    "           'WorkLifeBalance', 'BusinessTravel', 'JobLevel', 'StockOptionLevel']\n",
    "\n",
    "#Liste des variables qualitatives nominales\n",
    "var_nom = ['Department', 'Education', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4e2bcf42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:51:47.304243Z",
     "start_time": "2023-03-22T18:51:47.298056Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Séparation du dataset en jeux d'entraînement et de test\n",
    "X = df.drop('Attrition', axis=1)\n",
    "y = df['Attrition']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=7, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e727f532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:51:51.506874Z",
     "start_time": "2023-03-22T18:51:51.454346Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Encodage des variables nominales \n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "\n",
    "for var in var_nom:\n",
    "    ohe_train = ohe.fit_transform(X_train[[var]])\n",
    "    X_train = pd.concat([X_train, ohe_train],axis=1).drop(columns=[var])\n",
    "    ohe_test = ohe.transform(X_test[[var]])\n",
    "    X_test = pd.concat([X_test, ohe_test],axis=1).drop(columns=[var])\n",
    "\n",
    "#Encodage des variables ordinales\n",
    "encoder = OrdinalEncoder(categories=[[0,1,2,3,4,5]], \n",
    "                         handle_unknown='use_encoded_value',\n",
    "                         unknown_value=99)\n",
    "\n",
    "for var in var_ord:\n",
    "    X_train[[var]] = encoder.fit_transform(X_train[[var]])\n",
    "    X_test[[var]] = encoder.transform(X_test[[var]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a97e84f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:51:54.129950Z",
     "start_time": "2023-03-22T18:51:54.091377Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Redimensionnement des variables quantitatives\n",
    "scaler = RobustScaler()\n",
    "\n",
    "for var in var_quant:\n",
    "    X_train[[var]] = scaler.fit_transform(X_train[[var]])\n",
    "    X_test[[var]] = scaler.transform(X_test[[var]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f25e0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les variables n'ayant pas de distribution gaussienne (hormis Age) et le jeu de données contenant de nombreux outliers RobustScaler est plus approprié que StandardScaler et MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec0698",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (a) Pour chaque approche, avec les hyper-paramètres par défaut, évaluez la prédiction du churn sur la base de l’AUC (Area Under the Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7d26a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La courbe ROC (Receiver operating characteristic) permet de mesurer la performance d'un classifieur en contrebalançant la proportion de vrais positifs correctement prédits (recall ou sensitivity) par la proportion de vrais négatifs correctement prédits (specificity ou inverse de la précision). Le meilleur algorithme maximise l'aire sous la courbe ROC: l'AUC. \n",
    "\n",
    "Cependant utiliser la courbe ROC et l'AUC lorsque le jeu de données est déséquilibré pose problème (cf. Saito, T., & Rehmsmeier, M. (2015). The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. PloS one, 10(3), e0118432. https://doi.org/10.1371/journal.pone.0118432). La courbe Precision-Recall (PR) et le PR AUC sont plus adaptés. Il s'agit de la moyenne des précisions sur les classes, calculée à chaque seuil de recall.\n",
    "\n",
    "Dans notre cas, la PR AUC (average precision) est donc une meilleure mesure pour l'instant (avant d'essayer des techniques d'upsampling et de downsampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b5e2678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:52:12.355054Z",
     "start_time": "2023-03-22T18:52:03.071525Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree \n",
      "Average precision (PR AUC): 0.8477093505328502 \n",
      "\n",
      "LogisiticRegression \n",
      "Average precision (PR AUC): 0.39658224485841764 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC (linear) \n",
      "Average precision (PR AUC): 0.3101622808961998 \n",
      "\n",
      "SVC (rbf) \n",
      "Average precision (PR AUC): 0.5648236925228558 \n",
      "\n",
      "SVC (poly) \n",
      "Average precision (PR AUC): 0.5275688025481712 \n",
      "\n",
      "SVC (sigmoid) \n",
      "Average precision (PR AUC): 0.2705333872439934 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Algorithmes à utiliser\n",
    "clfs = {'DecisionTree': DecisionTreeClassifier(random_state=7),\n",
    "        'LogisiticRegression': LogisticRegression(random_state=7),\n",
    "        'SVC (linear)': SVC(kernel='linear', random_state=7),\n",
    "        'SVC (rbf)': SVC(kernel='rbf', random_state=7),\n",
    "        'SVC (poly)': SVC(kernel='poly', random_state=7),\n",
    "        'SVC (sigmoid)': SVC(kernel='sigmoid', random_state=7)}\n",
    "\n",
    "#Evaluation de la performance de chaque algorithme à partir de l'average precision (PR AUC)\n",
    "for key, clf in clfs.items():\n",
    "    clf_results = cross_validate(clf, X_train, y_train, scoring='average_precision', cv=5)\n",
    "    print(key, \n",
    "          \"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean(),\n",
    "          \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f96ecfb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "DecisionTree obtient de bons résultats par défaut mais il est probablement en overfitting avec une profondeur maximale (le paramètre max_depth est fixé à None par défaut). Les résultats des autres modèles ne sont pas bons mais le SVC avec le kernel rbf semble le plus prometteur.\n",
    "\n",
    "L'utilisation de différents hyper-paramètres peut permettre d'améliorer ces modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b06257",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (b) Pour chaque approche, définissez un modèle performant en recherchant de bons hyper-paramètres via un grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e000b71",
   "metadata": {
    "hidden": true
   },
   "source": [
    "L'hyper-paramètre 'class_weight' fixé à 'balanced' permet de limiter le déséquilibre et de donner plus de poids à une classification correcte de la classe minortiaire.\n",
    "\n",
    "Le paramètre refit='f1' signifie que le score qui doit être optimisé est le F1 score. L'AUC est simplement enregistrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f227a30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:53:13.610792Z",
     "start_time": "2023-03-22T18:53:12.104631Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 20, 'random_state': 7} \n",
      "Average precision (PR AUC): 0.8478533070322941\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle d'arbre de décision\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'criterion': ['gini', 'entropy'], \n",
    "              'max_depth': [5,10,15,20,25,30,35,40,46],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_tree, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f25ec8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:53:31.880452Z",
     "start_time": "2023-03-22T18:53:22.471587Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'C': 0.0001, 'class_weight': 'balanced', 'penalty': 'l2', 'random_state': 7, 'solver': 'sag'} \n",
      "Average precision (PR AUC): 0.4014044360989607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "125 fits failed out of a total of 225.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.4012497  0.40140444 0.40043695        nan        nan 0.16091298\n",
      "        nan        nan        nan 0.39073109 0.39022314 0.39097527\n",
      "        nan        nan 0.16091298        nan        nan        nan\n",
      " 0.37273612 0.37869723 0.38541721        nan        nan 0.38074202\n",
      "        nan        nan        nan 0.36127674 0.37490051 0.38420039\n",
      "        nan        nan 0.3841319         nan        nan        nan\n",
      " 0.36081447 0.37489641 0.38420705        nan        nan 0.38419771\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/utilisateur/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.41473131 0.41468671 0.41370094        nan        nan 0.16091298\n",
      "        nan        nan        nan 0.40101135 0.40102799 0.40090554\n",
      "        nan        nan 0.16091298        nan        nan        nan\n",
      " 0.39372386 0.39675177 0.40055433        nan        nan 0.39779062\n",
      "        nan        nan        nan 0.38377894 0.39431917 0.39955438\n",
      "        nan        nan 0.39953083        nan        nan        nan\n",
      " 0.38366709 0.39423932 0.3995282         nan        nan 0.3995289\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle de régression logistique\n",
    "clf_logreg = LogisticRegression()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'penalty':['l2', 'l1', 'elasticnet'],\n",
    "              'C':[0.0001,0.001,0.1,10,100],\n",
    "              'solver': ['lbfgs', 'sag', 'saga'],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_logreg, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55b3ea89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:21:36.333174Z",
     "start_time": "2023-03-22T17:18:24.188886Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'C': 1e-05, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf', 'random_state': 7} \n",
      "Average precision (PR AUC): 0.9666830134060511\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle SVC avec kernel\n",
    "clf_svc = SVC()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'C': [1e-6, 1e-5, 1e-4], \n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "              'gamma': ['scale', 'auto', 1, 10, 100],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_svc, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2db418d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:27:13.074329Z",
     "start_time": "2023-03-22T17:27:12.386601Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.5796955880876223\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du meilleur modèle\n",
    "clf = SVC(C=1e-05, gamma=1, kernel='rbf', class_weight='balanced', random_state=7)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "871735bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:27:22.845511Z",
     "start_time": "2023-03-22T17:27:22.842379Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148 588]\n",
      " [ 28 113]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15b4e872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:27:31.980036Z",
     "start_time": "2023-03-22T17:27:31.974056Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.20      0.32       736\n",
      "           1       0.16      0.80      0.27       141\n",
      "\n",
      "    accuracy                           0.30       877\n",
      "   macro avg       0.50      0.50      0.30       877\n",
      "weighted avg       0.73      0.30      0.32       877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99535a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T00:10:38.629406Z",
     "start_time": "2023-03-21T00:10:38.627142Z"
    },
    "hidden": true
   },
   "source": [
    "Le SVC était probablement en overfitting, le paramètre C a favorisé un modèle complexe qui généralise mal. Essayons le deuxième meilleur modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcdd382e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:29:13.218819Z",
     "start_time": "2023-03-22T17:29:13.142007Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.3457831545503959\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du 2ème meilleur modèle\n",
    "clf = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=20, random_state=7)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa9de956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:29:17.967191Z",
     "start_time": "2023-03-22T17:29:17.963746Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[663  73]\n",
      " [ 66  75]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "018c99bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:29:28.902398Z",
     "start_time": "2023-03-22T17:29:28.896466Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       736\n",
      "           1       0.51      0.53      0.52       141\n",
      "\n",
      "    accuracy                           0.84       877\n",
      "   macro avg       0.71      0.72      0.71       877\n",
      "weighted avg       0.84      0.84      0.84       877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366ab0f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lui aussi était en overfitting comme l'indique l'écart de PR AUC entre le jeu d'entraînement et le jeu test mais le rapport de classification est bien meilleur avec un F1 score macro de 0,71. Les différents hyperparamètres ont forcé le modèle à trouver des exemples de la classe minoritaire et il a moins de faux négatifs que les autres. La précision sur la classe minoritaire n'est toutefois que de 51%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

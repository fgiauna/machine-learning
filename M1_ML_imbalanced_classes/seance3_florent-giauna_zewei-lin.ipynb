{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bdcaac",
   "metadata": {},
   "source": [
    "Florent Giauna (AMSD) et Zewei Lin (MLSD)\n",
    "\n",
    "Appentissage supervisé pour des données avec classes déséquilibrées\n",
    "\n",
    "Séance 3 - Prédiction de churn, Partie II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e6b59b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:29:02.456152Z",
     "start_time": "2023-03-23T07:29:01.718099Z"
    }
   },
   "outputs": [],
   "source": [
    "#Librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Pré-traitement\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#Sélection de modèles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Modèles\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Métriques\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da61c30",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataset : Credit fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab913eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:54:26.921320Z",
     "start_time": "2023-03-22T18:54:25.782336Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Chargement des données \n",
    "df = pd.read_csv('data/creditcard_v2.csv')\n",
    "\n",
    "#Séparation du dataset en jeux d'entraînement et de test\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=7, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9653bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T18:54:33.170526Z",
     "start_time": "2023-03-22T18:54:31.920063Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Liste des variables\n",
    "var_list = list(X_train)\n",
    "    \n",
    "#Redimensionnement des variables quantitatives\n",
    "scaler = RobustScaler()\n",
    "\n",
    "for var in var_list:\n",
    "    X_train[[var]] = scaler.fit_transform(X_train[[var]])\n",
    "    X_test[[var]] = scaler.transform(X_test[[var]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c3ad1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les variables contenant de nombreux outliers RobustScaler est plus approprié que StandardScaler et MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31e50f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La courbe ROC (Receiver operating characteristic) permet de mesurer la performance d'un classifieur en contrebalançant la proportion de vrais positifs correctement prédits (recall ou sensitivity) par la proportion de vrais négatifs correctement prédits (specificity ou inverse de la précision). Le meilleur algorithme maximise l'aire sous la courbe ROC: l'AUC. \n",
    "\n",
    "Cependant utiliser la courbe ROC et l'AUC lorsque le jeu de données est déséquilibré pose problème (cf. Saito, T., & Rehmsmeier, M. (2015). The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. PloS one, 10(3), e0118432. https://doi.org/10.1371/journal.pone.0118432). La courbe Precision-Recall (PR) et le PR AUC sont plus adaptés. Il s'agit de la moyenne des précisions sur les classes, calculée à chaque seuil de recall.\n",
    "\n",
    "Dans notre cas, la PR AUC (average precision) est donc une meilleure mesure pour l'instant (avant d'essayer des techniques d'upsampling et de downsampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76bba78",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13363388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T19:22:16.600389Z",
     "start_time": "2023-03-22T18:55:07.763208Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 50, 'random_state': 7} \n",
      "Average precision (PR AUC): 0.8427836737342986\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle RandomForest\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'n_estimators': [25, 50],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [13,15,17],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_rf, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640cff54",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3435ef",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le paramètre 'scale_pos_weight' permet de donner plus de poids au gradient de la classe positive. Les erreurs commises par le modèle sur la classe positive sont considérées comme plus importantes. Cela peut l'aider à obtenir de meilleures performances sur la classe minoritaire. \n",
    "\n",
    "La documentation de XGBoost suggère de fixer la valeur du poids en divisant le nombre d'exemples de la classe majoritaire par le nombre d'exemples de la classe minoritaire (dans le jeu d'entraînement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4f9b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T20:40:26.283341Z",
     "start_time": "2023-03-22T20:23:11.189801Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 50, 'random_state': 7, 'reg_alpha': 0.001, 'reg_lambda': 0.001, 'scale_pos_weight': 0.0017322412299792043} \n",
      "Average precision (PR AUC): 0.7525885963156458\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle XGBoost\n",
    "clf_xgb = XGBClassifier()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'learning_rate': [0.1, 0.3],\n",
    "              'max_depth': [3,5,7],\n",
    "              'n_estimators': [25, 50],\n",
    "              'reg_alpha': [0.001,0.01],\n",
    "              'reg_lambda': [0.001,0.01],\n",
    "              'scale_pos_weight': [y_train.value_counts()[0] /\n",
    "                                   y_train.value_counts()[1]],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_xgb, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ebc35",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce4514",
   "metadata": {
    "hidden": true
   },
   "source": [
    "XGBoost a des résultats un peu en dessous de RandomForest mais ce dernier prend beaucoup plus de temps (27 min pour 49 modèles contre 17 min pour 121 modèles avec XGBoost). XGBoost semble être une meilleure option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02037d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T21:41:22.638179Z",
     "start_time": "2023-03-22T21:40:44.764993Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.8207177563406534\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du meilleur modèle\n",
    "clf = XGBClassifier(learning_rate=0.3, \n",
    "                    max_depth=5, \n",
    "                    n_estimators=50, \n",
    "                    random_state=7,\n",
    "                    reg_alpha=0.01, \n",
    "                    reg_lambda=0.01, \n",
    "                    scale_pos_weight=(y_train.value_counts()[0] / \n",
    "                                      y_train.value_counts()[1]))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "feb63f2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T21:43:26.718227Z",
     "start_time": "2023-03-22T21:43:26.710683Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56851    13]\n",
      " [   22    76]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5b382b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T21:43:27.968280Z",
     "start_time": "2023-03-22T21:43:27.929627Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.85      0.78      0.81        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.89      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15597c3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ce résultat est jusqu'à présent le meilleur que nous ayons obtenu sur ce jeu de données. La précision sur la classe minoritaire est désormais de 85%, mais le recall a diminué. Comparons avec le meilleur RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "092468a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T21:51:37.884471Z",
     "start_time": "2023-03-22T21:50:12.614896Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.8251964392069787\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du meilleur RandomForest\n",
    "clf = RandomForestClassifier(class_weight='balanced', \n",
    "                             criterion='entropy', \n",
    "                             max_depth=15, \n",
    "                             n_estimators=50,\n",
    "                             random_state=7)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0eb7cf34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T21:51:54.622628Z",
     "start_time": "2023-03-22T21:51:54.613994Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56861     3]\n",
      " [   30    68]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4e87be1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T21:51:57.508479Z",
     "start_time": "2023-03-22T21:51:57.469390Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.96      0.69      0.80        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.85      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da61b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La précision sur la classe minoritaire est de 96%, mais le recall et le F1 score sur cette classe sont en dessous de ceux obtenus avec XGBoost. En outre le modèle requiert deux fois plus de temps pour s'exécuter.\n",
    "\n",
    "XGBoost est donc un meilleur choix mais les techniques de rééquilibrage doivent encore être testées avant de mettre ce modèle en production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a425a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataset : Bank marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f5c076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:30:53.875181Z",
     "start_time": "2023-03-23T07:30:53.825162Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Chargement des données \n",
    "df = pd.read_csv('data/bank-additional-full_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20ba7c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:30:54.578849Z",
     "start_time": "2023-03-23T07:30:54.560828Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Séparation du dataset en jeux d'entraînement et de test\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=7, shuffle=True, stratify=y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dee18689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:30:55.489685Z",
     "start_time": "2023-03-23T07:30:55.485996Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Liste des variables catégorielles nominales\n",
    "var_nom = list(X_train.select_dtypes(['object']).columns)\n",
    "var_nom += ['age', 'duration', 'pdays']\n",
    "\n",
    "#Liste des variables quantitatives\n",
    "var_quant = ['campaign', 'cons.conf.idx', 'cons.price.idx', 'emp.var.rate', \n",
    "             'euribor3m', 'nr.employed', 'previous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e8995e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:30:57.246135Z",
     "start_time": "2023-03-23T07:30:57.051587Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Encodage des variables nominales \n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "\n",
    "for var in var_nom:\n",
    "    ohe_train = ohe.fit_transform(X_train[[var]])\n",
    "    X_train = pd.concat([X_train, ohe_train],axis=1).drop(columns=[var])\n",
    "    ohe_test = ohe.transform(X_test[[var]])\n",
    "    X_test = pd.concat([X_test, ohe_test],axis=1).drop(columns=[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa6a2584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:31:10.284484Z",
     "start_time": "2023-03-23T07:31:10.218146Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Redimensionnement des variables quantitatives\n",
    "scaler = RobustScaler()\n",
    "\n",
    "for var in var_quant:\n",
    "    X_train[[var]] = scaler.fit_transform(X_train[[var]])\n",
    "    X_test[[var]] = scaler.transform(X_test[[var]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8bb1c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les variables n'ayant pas de distribution gaussienne et le jeu de données contenant de nombreux outliers RobustScaler est plus approprié que StandardScaler et MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91173a9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La courbe ROC (Receiver operating characteristic) permet de mesurer la performance d'un classifieur en contrebalançant la proportion de vrais positifs correctement prédits (recall ou sensitivity) par la proportion de vrais négatifs correctement prédits (specificity ou inverse de la précision). Le meilleur algorithme maximise l'aire sous la courbe ROC: l'AUC. \n",
    "\n",
    "Cependant utiliser la courbe ROC et l'AUC lorsque le jeu de données est déséquilibré pose problème (cf. Saito, T., & Rehmsmeier, M. (2015). The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. PloS one, 10(3), e0118432. https://doi.org/10.1371/journal.pone.0118432). La courbe Precision-Recall (PR) et le PR AUC sont plus adaptés. Il s'agit de la moyenne des précisions sur les classes, calculée à chaque seuil de recall.\n",
    "\n",
    "Dans notre cas, la PR AUC (average precision) est donc une meilleure mesure pour l'instant (avant d'essayer des techniques d'upsampling et de downsampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016970ff",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f484682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:34:01.066094Z",
     "start_time": "2023-03-23T07:32:02.110066Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'n_estimators': 100, 'random_state': 7} \n",
      "Average precision (PR AUC): 0.5823520663192963\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle RandomForest\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'n_estimators': [50,100],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [5,7,9,11,15,30],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_rf, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192f31b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f570fe2e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le paramètre 'scale_pos_weight' permet de donner plus de poids au gradient de la classe positive. Les erreurs commises par le modèle sur la classe positive sont considérées comme plus importantes. Cela peut l'aider à obtenir de meilleures performances sur la classe minoritaire. \n",
    "\n",
    "La documentation de XGBoost suggère de fixer la valeur du poids en divisant le nombre d'exemples de la classe majoritaire par le nombre d'exemples de la classe minoritaire (dans le jeu d'entraînement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5eae7b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T22:43:44.214958Z",
     "start_time": "2023-03-22T22:37:23.917582Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100, 'random_state': 7, 'reg_alpha': 0.01, 'reg_lambda': 0.01, 'scale_pos_weight': 7.876616379310345} \n",
      "Average precision (PR AUC): 0.5925114736928816\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle XGBoost\n",
    "clf_xgb = XGBClassifier()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'learning_rate': [0.3],\n",
    "              'max_depth': [1,3,5,15,30],\n",
    "              'n_estimators': [100],\n",
    "              'reg_alpha': [0.01,0.1],\n",
    "              'reg_lambda': [0.01,0.1],\n",
    "              'scale_pos_weight': [y_train.value_counts()[0] /\n",
    "                                   y_train.value_counts()[1]],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_xgb, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b1aff",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523e1e6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "RandomForest a des résultats un peu en dessous de XGBoost mais ce dernier prend beaucoup plus de temps (6 min pour 100 modèles contre 2 min pour 100 modèles avec RandomForest). RandomForest semble être une meilleure option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9575200b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:37:17.016914Z",
     "start_time": "2023-03-23T07:37:13.164171Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.5671260333037841\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du meilleur modèle\n",
    "clf = RandomForestClassifier(class_weight='balanced', \n",
    "                             criterion='entropy', \n",
    "                             max_depth=9, \n",
    "                             n_estimators=100,\n",
    "                             random_state=7)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed632daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:37:22.056243Z",
     "start_time": "2023-03-23T07:37:22.052599Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6111 1199]\n",
      " [ 160  768]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8ae8c56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T22:50:28.060351Z",
     "start_time": "2023-03-22T22:50:28.042652Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90      7310\n",
      "           1       0.39      0.83      0.53       928\n",
      "\n",
      "    accuracy                           0.84      8238\n",
      "   macro avg       0.68      0.83      0.72      8238\n",
      "weighted avg       0.91      0.84      0.86      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75395d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ce résultat est jusqu'à présent le meilleur que nous ayons obtenu sur ce jeu de données. Mais il y a encore énormément de faux négatifs et la précision sur la classe minoritaire n'a pas beaucoup augmenté (39% contre 34% précédemment), mais il y a encore énormément de faux négatifs. Comparons avec le meilleur XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9bd8811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:43:23.932938Z",
     "start_time": "2023-03-23T07:43:20.435413Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.5511998973945706\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du meilleur XGBoost\n",
    "clf = XGBClassifier(learning_rate=0.3, \n",
    "                    max_depth=3, \n",
    "                    n_estimators=100, \n",
    "                    random_state=7,\n",
    "                    reg_alpha=0.01, \n",
    "                    reg_lambda=0.01, \n",
    "                    scale_pos_weight=(y_train.value_counts()[0] / \n",
    "                                      y_train.value_counts()[1]))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87e8f701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:43:26.174725Z",
     "start_time": "2023-03-23T07:43:26.171152Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5961 1349]\n",
      " [ 162  766]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7b4d8c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:43:27.201407Z",
     "start_time": "2023-03-23T07:43:27.189837Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89      7310\n",
      "           1       0.36      0.83      0.50       928\n",
      "\n",
      "    accuracy                           0.82      8238\n",
      "   macro avg       0.67      0.82      0.70      8238\n",
      "weighted avg       0.90      0.82      0.84      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136b7c6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les résultats sont moins bons alors que le modèle est plus long à s'exécuter.\n",
    "\n",
    "RandomForest est donc un meilleur choix mais les techniques de rééquilibrage doivent encore être testées avant de mettre ce modèle en production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63906f82",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataset : Employee attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43bf574e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:45:45.343086Z",
     "start_time": "2023-03-23T07:45:45.326786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Chargement des données \n",
    "df = pd.read_csv('data/whole_data_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81fba04d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:45:46.435687Z",
     "start_time": "2023-03-23T07:45:46.432361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Liste des variables quantitatives\n",
    "var_quant = ['Age', 'DistanceFromHome', 'MonthlyIncome', 'NumCompaniesWorked', \n",
    "            'PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear', \n",
    "            'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "\n",
    "#Liste des variables qualitatives\n",
    "var_cat = ['JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction',\n",
    "           'WorkLifeBalance', 'BusinessTravel', 'Department', 'Education', \n",
    "           'EducationField', 'Gender', 'MaritalStatus', 'JobLevel', 'JobRole', 'StockOptionLevel']\n",
    "\n",
    "#Liste des variables qualitatives ordinales\n",
    "var_ord = ['JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction',\n",
    "           'WorkLifeBalance', 'BusinessTravel', 'JobLevel', 'StockOptionLevel']\n",
    "\n",
    "#Liste des variables qualitatives nominales\n",
    "var_nom = ['Department', 'Education', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e2bcf42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:45:47.984668Z",
     "start_time": "2023-03-23T07:45:47.977635Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Séparation du dataset en jeux d'entraînement et de test\n",
    "X = df.drop('Attrition', axis=1)\n",
    "y = df['Attrition']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=7, shuffle=True, stratify=y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e727f532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:45:50.989486Z",
     "start_time": "2023-03-23T07:45:50.939889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Encodage des variables nominales \n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "\n",
    "for var in var_nom:\n",
    "    ohe_train = ohe.fit_transform(X_train[[var]])\n",
    "    X_train = pd.concat([X_train, ohe_train],axis=1).drop(columns=[var])\n",
    "    ohe_test = ohe.transform(X_test[[var]])\n",
    "    X_test = pd.concat([X_test, ohe_test],axis=1).drop(columns=[var])\n",
    "\n",
    "#Encodage des variables ordinales\n",
    "encoder = OrdinalEncoder(categories=[[0,1,2,3,4,5]], \n",
    "                         handle_unknown='use_encoded_value',\n",
    "                         unknown_value=99)\n",
    "\n",
    "for var in var_ord:\n",
    "    X_train[[var]] = encoder.fit_transform(X_train[[var]])\n",
    "    X_test[[var]] = encoder.transform(X_test[[var]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a97e84f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T07:45:57.478478Z",
     "start_time": "2023-03-23T07:45:57.440250Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Redimensionnement des variables quantitatives\n",
    "scaler = RobustScaler()\n",
    "\n",
    "for var in var_quant:\n",
    "    X_train[[var]] = scaler.fit_transform(X_train[[var]])\n",
    "    X_test[[var]] = scaler.transform(X_test[[var]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f25e0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les variables n'ayant pas de distribution gaussienne (hormis Age) et le jeu de données contenant de nombreux outliers RobustScaler est plus approprié que StandardScaler et MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b7374b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La courbe ROC (Receiver operating characteristic) permet de mesurer la performance d'un classifieur en contrebalançant la proportion de vrais positifs correctement prédits (recall ou sensitivity) par la proportion de vrais négatifs correctement prédits (specificity ou inverse de la précision). Le meilleur algorithme maximise l'aire sous la courbe ROC: l'AUC. \n",
    "\n",
    "Cependant utiliser la courbe ROC et l'AUC lorsque le jeu de données est déséquilibré pose problème (cf. Saito, T., & Rehmsmeier, M. (2015). The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. PloS one, 10(3), e0118432. https://doi.org/10.1371/journal.pone.0118432). La courbe Precision-Recall (PR) et le PR AUC sont plus adaptés. Il s'agit de la moyenne des précisions sur les classes, calculée à chaque seuil de recall.\n",
    "\n",
    "Dans notre cas, la PR AUC (average precision) est donc une meilleure mesure pour l'instant (avant d'essayer des techniques d'upsampling et de downsampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d20cd47",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9a8792b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T08:03:31.039135Z",
     "start_time": "2023-03-23T08:03:03.629466Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 100, 'random_state': 7} \n",
      "Average precision (PR AUC): 0.9755055076740135\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle RandomForest\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'n_estimators': [50,100],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [1,5,10,15,20,25,35,46],\n",
    "              'class_weight': ['balanced'],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_rf, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a867ba",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683d88e9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le paramètre 'scale_pos_weight' permet de donner plus de poids au gradient de la classe positive. Les erreurs commises par le modèle sur la classe positive sont considérées comme plus importantes. Cela peut l'aider à obtenir de meilleures performances sur la classe minoritaire. \n",
    "\n",
    "La documentation de XGBoost suggère de fixer la valeur du poids en divisant le nombre d'exemples de la classe majoritaire par le nombre d'exemples de la classe minoritaire (dans le jeu d'entraînement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b4e93d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T08:15:29.261532Z",
     "start_time": "2023-03-23T08:14:56.666826Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure configuration: {'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 100, 'random_state': 7, 'reg_alpha': 0.01, 'reg_lambda': 0.01, 'scale_pos_weight': 5.214539007092198} \n",
      "Average precision (PR AUC): 0.96372038264088\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du modèle XGBoost\n",
    "clf_xgb = XGBClassifier()\n",
    "\n",
    "#Création de la grille de paramètres à tester\n",
    "param_grid = {'learning_rate': [0.3],\n",
    "              'max_depth': [5,10,15,20,25,35,46],\n",
    "              'n_estimators': [100],\n",
    "              'reg_alpha': [0.01,0.1],\n",
    "              'reg_lambda': [0.01,0.1],\n",
    "              'scale_pos_weight': [y_train.value_counts()[0] /\n",
    "                                   y_train.value_counts()[1]],\n",
    "              'random_state': [7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf_xgb, \n",
    "                    param_grid=param_grid,\n",
    "                    scoring='average_precision',\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleure configuration:\", grid.best_params_, \n",
    "      \"\\nAverage precision (PR AUC):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6a8d0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f75b54",
   "metadata": {
    "hidden": true
   },
   "source": [
    "RandomForest a de meilleurs résultats que XGBoost et prend moins de temps pour s'exécuter (27 s pour 144 modèles contre 6 min pour 100 modèles contre 53 s pour 169 modèles avec XGBoost). Mais RandomForest semble un peu plus complexe que XGBoost (profondeur de 20 contre 15). Comparons leurs résultats sur le jeu test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3caebb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T08:20:27.127739Z",
     "start_time": "2023-03-23T08:20:25.545520Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.6803778784195469\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du meilleur RandomForest\n",
    "clf = RandomForestClassifier(class_weight='balanced', \n",
    "                             criterion='entropy', \n",
    "                             max_depth=20,\n",
    "                             n_estimators=100,\n",
    "                             random_state=7)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53731bf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T08:22:25.352913Z",
     "start_time": "2023-03-23T08:22:25.349524Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[730   6]\n",
      " [ 89  52]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92774b36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T08:22:30.025028Z",
     "start_time": "2023-03-23T08:22:30.019416Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94       736\n",
      "           1       0.90      0.37      0.52       141\n",
      "\n",
      "    accuracy                           0.89       877\n",
      "   macro avg       0.89      0.68      0.73       877\n",
      "weighted avg       0.89      0.89      0.87       877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c0328",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ce résultat est jusqu'à présent le meilleur que nous ayons obtenu sur ce jeu de données. La précision sur la classe minoritaire est désormais de 90%, au détriment du recall (passé de 53% à 37%). Il y a plus de faux positifs mais beaucoup moins de faux négatifs, ce qui est plus souhaitable dans notre cas. Comparons avec le meilleur XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e69c4835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T08:27:38.686094Z",
     "start_time": "2023-03-23T08:27:37.197297Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average precision (PR AUC): 0.6449355663065015\n"
     ]
    }
   ],
   "source": [
    "#Instanciation du meilleur XGBoost\n",
    "clf = XGBClassifier(learning_rate=0.3, \n",
    "                    max_depth=15, \n",
    "                    n_estimators=100, \n",
    "                    random_state=7,\n",
    "                    reg_alpha=0.01, \n",
    "                    reg_lambda=0.01, \n",
    "                    scale_pos_weight=(y_train.value_counts()[0] / \n",
    "                                      y_train.value_counts()[1]))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Classification du jeu test\n",
    "pred = cross_val_predict(clf, X_test, y_test, cv=5)\n",
    "\n",
    "#Résultats\n",
    "clf_results = cross_validate(clf, X_test, y_test, scoring='average_precision', cv=5)\n",
    "print(\"\\nAverage precision (PR AUC):\", clf_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1244f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T08:27:44.081975Z",
     "start_time": "2023-03-23T08:27:44.078583Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[699  37]\n",
      " [ 69  72]]\n"
     ]
    }
   ],
   "source": [
    "#Matrice de confusion\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a10f5e8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T08:27:45.352818Z",
     "start_time": "2023-03-23T08:27:45.346791Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       736\n",
      "           1       0.66      0.51      0.58       141\n",
      "\n",
      "    accuracy                           0.88       877\n",
      "   macro avg       0.79      0.73      0.75       877\n",
      "weighted avg       0.87      0.88      0.87       877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rapport de classification\n",
    "print(classification_report(y_test, pred, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544da373",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le F1 score macro average est un peu meilleur. Ce modèle a un meilleur recall sur la classe minoritaire mais sa précision sur cette classe est très en dessous du RandomForest. Il génère plus de faux négatifs. \n",
    "\n",
    "RandomForest semble être un meilleur choix mais les techniques de rééquilibrage doivent encore être testées avant de mettre ce modèle en production."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
